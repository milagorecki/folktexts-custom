{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore how to change prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgorecki/opt/miniconda3/envs/monoc-py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.0.26'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import folktexts\n",
    "from folktexts import prompting\n",
    "\n",
    "#load the dataset\n",
    "from folktexts.acs.acs_tasks import ACSTaskMetadata\n",
    "from folktexts.acs.acs_dataset import ACSDataset\n",
    "\n",
    "folktexts.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ACS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All ACS prediction tasks\n",
    "ACS_TASKS = (\n",
    "    \"ACSIncome\",\n",
    "    \"ACSEmployment\",\n",
    "    \"ACSMobility\",\n",
    "    \"ACSTravelTime\",\n",
    "    \"ACSPublicCoverage\",\n",
    ")\n",
    "\n",
    "data_dir = Path(\"../llm_fairness/folktexts/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-defined task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACSTaskMetadata(name='ACSIncome', features=['AGEP', 'COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'RELP', 'WKHP', 'SEX', 'RAC1P'], target='PINCP', cols_to_text={'AGEP': <folktexts.col_to_text.ColumnToText object at 0x117e7a0e0>, 'COW': <folktexts.col_to_text.ColumnToText object at 0x117e7a0b0>, 'SCHL': <folktexts.col_to_text.ColumnToText object at 0x117e7a080>, 'MAR': <folktexts.col_to_text.ColumnToText object at 0x117e7a800>, 'OCCP': <folktexts.col_to_text.ColumnToText object at 0x117e7b430>, 'POBP': <folktexts.col_to_text.ColumnToText object at 0x117e79c90>, 'RELP': <folktexts.col_to_text.ColumnToText object at 0x117e79cf0>, 'WKHP': <folktexts.col_to_text.ColumnToText object at 0x117e79d20>, 'SEX': <folktexts.col_to_text.ColumnToText object at 0x117e79840>, 'RAC1P': <folktexts.col_to_text.ColumnToText object at 0x117e797e0>, 'PINCP': <folktexts.col_to_text.ColumnToText object at 0x117e796c0>, 'PINCP>50000': <folktexts.col_to_text.ColumnToText object at 0x117e79120>, 'PUBCOV': <folktexts.col_to_text.ColumnToText object at 0x117e79000>, 'PUBCOV==1': <folktexts.col_to_text.ColumnToText object at 0x117e78220>, 'DIS': <folktexts.col_to_text.ColumnToText object at 0x117e78250>, 'ESP': <folktexts.col_to_text.ColumnToText object at 0x117e78280>, 'CIT': <folktexts.col_to_text.ColumnToText object at 0x117e788b0>, 'MIG': <folktexts.col_to_text.ColumnToText object at 0x117e78940>, 'MIG!=1': <folktexts.col_to_text.ColumnToText object at 0x117e7b8e0>, 'MIL': <folktexts.col_to_text.ColumnToText object at 0x117e7b910>, 'ANC': <folktexts.col_to_text.ColumnToText object at 0x117e7baf0>, 'ANC1P': <folktexts.col_to_text.ColumnToText object at 0x117e7bb50>, 'NATIVITY': <folktexts.col_to_text.ColumnToText object at 0x117e7bd90>, 'LANX': <folktexts.col_to_text.ColumnToText object at 0x117e7bdf0>, 'LANP': <folktexts.col_to_text.ColumnToText object at 0x117e94070>, 'ENG': <folktexts.col_to_text.ColumnToText object at 0x117e940d0>, 'NOP': <folktexts.col_to_text.ColumnToText object at 0x117e942b0>, 'DEAR': <folktexts.col_to_text.ColumnToText object at 0x117e94640>, 'DEYE': <folktexts.col_to_text.ColumnToText object at 0x117e946a0>, 'DREM': <folktexts.col_to_text.ColumnToText object at 0x117e947c0>, 'ESR': <folktexts.col_to_text.ColumnToText object at 0x117e94a30>, 'ESR==1': <folktexts.col_to_text.ColumnToText object at 0x117e94eb0>, 'ST': <folktexts.col_to_text.ColumnToText object at 0x117e94ee0>, 'HISP': <folktexts.col_to_text.ColumnToText object at 0x117e94f10>, 'FER': <folktexts.col_to_text.ColumnToText object at 0x117e94f40>, 'JWMNP': <folktexts.col_to_text.ColumnToText object at 0x117e95060>, 'JWMNP>20': <folktexts.col_to_text.ColumnToText object at 0x117e95240>, 'JWTR': <folktexts.col_to_text.ColumnToText object at 0x117e95270>, 'POVPIP': <folktexts.col_to_text.ColumnToText object at 0x117e952a0>, 'POVPIP<250': <folktexts.col_to_text.ColumnToText object at 0x117e958a0>, 'GCL': <folktexts.col_to_text.ColumnToText object at 0x117e95900>, 'PUMA': <folktexts.col_to_text.ColumnToText object at 0x117e95a20>, 'POWPUMA': <folktexts.col_to_text.ColumnToText object at 0x117e95a80>, 'HINS2': <folktexts.col_to_text.ColumnToText object at 0x117e95ab0>, 'HINS2==1': <folktexts.col_to_text.ColumnToText object at 0x117e95d80>}, sensitive_attribute='RAC1P', target_threshold=Threshold(value=50000, op='>'), multiple_choice_qa=MultipleChoiceQA(column='PINCP>50000', text=\"What is this person's estimated yearly income?\", num_forward_passes=1, choices=(Choice(text='Below $50,000', data_value=0, numeric_value=None), Choice(text='Above $50,000', data_value=1, numeric_value=None)), _answer_keys_source=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z')), direct_numeric_qa=DirectNumericQA(column='PINCP>50000', text=\"What is the probability that this person's estimated yearly income is above $50,000 ?\", num_forward_passes=2, answer_probability=True), description=\"predict whether an individual's income is above $50,000\", _use_numeric_qa=False, folktables_obj=<folktables.folktables.BasicProblem object at 0x117c942b0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_name = ACS_TASKS[0]\n",
    "#folktable tasks are created via ACSTaskMetadata.make_folktables_task()\n",
    "acs_task = ACSTaskMetadata.get_task(task_name)\n",
    "acs_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customize a task**\n",
    "\n",
    "```\n",
    "def make_task(\n",
    "        cls,\n",
    "        name: str,\n",
    "        description: str,\n",
    "        features: list[str],\n",
    "        target: str,\n",
    "        sensitive_attribute: str = None,\n",
    "        target_threshold: Threshold = None,\n",
    "        population_description: str = None,\n",
    "        folktables_obj: BasicProblem = None,\n",
    "        multiple_choice_qa: MultipleChoiceQA = None,\n",
    "        direct_numeric_qa: DirectNumericQA = None,\n",
    "    ) -> ACSTaskMetadata:\n",
    "```\n",
    "\n",
    "- possible to change the target column, the corresponding threshold and the question\n",
    "- possible to change the sensitive attribute\n",
    "- possible to change the features used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the ACS data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ACS data...\n"
     ]
    }
   ],
   "source": [
    "acs_dataset_configs = folktexts.benchmark.Benchmark.ACS_DATASET_CONFIGS.copy()\n",
    "\n",
    "dataset = ACSDataset.make_from_task(\n",
    "                task_name, cache_dir=data_dir, **acs_dataset_configs\n",
    ")\n",
    "\n",
    "X_train, y_train = dataset.get_train()\n",
    "X_test, y_test = dataset.get_test()\n",
    "s_test = None\n",
    "if dataset.task.sensitive_attribute is not None:\n",
    "    s_test = dataset.get_sensitive_attribute_data().loc[y_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features are currently stored as ColumnToText object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGEP, COW, SCHL, MAR, OCCP, POBP, RELP, WKHP, SEX, RAC1P, PINCP, PINCP>50000, PUBCOV, PUBCOV==1, DIS, ESP, CIT, MIG, MIG!=1, MIL, ANC, ANC1P, NATIVITY, LANX, LANP, ENG, NOP, DEAR, DEYE, DREM, ESR, ESR==1, ST, HISP, FER, JWMNP, JWMNP>20, JWTR, POVPIP, POVPIP<250, GCL, PUMA, POWPUMA, HINS2, HINS2==1, "
     ]
    }
   ],
   "source": [
    "import folktexts.acs.acs_columns as acs_cols\n",
    "from folktexts.col_to_text import ColumnToText as _ColumnToText\n",
    "\n",
    "for col_mapper in acs_cols.__dict__.values():\n",
    "    if isinstance(col_mapper, _ColumnToText):\n",
    "        print(col_mapper.name, end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each feature has the following signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (name: 'str', short_description: 'str', value_map: 'dict[object, str] | Callable' = None, question: 'QAInterface' = None, connector_verb: 'str' = 'is', verbalize: 'Callable' = None, missing_value_fill: 'str' = 'N/A', use_value_map_only: 'bool' = False)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from folktexts.acs.acs_tasks import acs_columns_map\n",
    "from inspect import signature\n",
    "signature(acs_columns_map['AGEP'].__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_columns_map['AGEP']._connector_verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt is composed of \n",
    "- [system prompt, if used for chat-based prompting]\n",
    "- a task description\n",
    "- a textual representation of the row in the data set\n",
    "- a question (multiple choice or direct numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AGEP       53.0\n",
       " COW         6.0\n",
       " SCHL       21.0\n",
       " MAR         1.0\n",
       " OCCP     2752.0\n",
       " POBP       36.0\n",
       " RELP        0.0\n",
       " WKHP       20.0\n",
       " SEX         1.0\n",
       " RAC1P       1.0\n",
       " Name: 1080377, dtype: float64,\n",
       " AGEP       53.0\n",
       " COW         6.0\n",
       " SCHL       21.0\n",
       " MAR         1.0\n",
       " OCCP     2752.0\n",
       " POBP       36.0\n",
       " RELP        0.0\n",
       " WKHP        NaN\n",
       " SEX         1.0\n",
       " RAC1P       1.0\n",
       " Name: 1080377, dtype: float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row = X_train.iloc[0]\n",
    "corrupted_row = example_row.copy()\n",
    "corrupted_row['WKHP'] = None\n",
    "example_row, corrupted_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The following data corresponds to a survey respondent. The survey was conducted among US residents in 2018. Please answer the question based on the information provided. The data provided is enough to reach an approximate answer.\\n',\n",
       " 'The following data corresponds to different survey respondents. The survey was conducted among US residents in 2018. Please answer each question based on the information provided. The data provided is enough to reach an approximate answer for each person.\\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompting.ACS_TASK_DESCRIPTION, prompting.ACS_FEW_SHOT_TASK_DESCRIPTION\n",
    "# note: 2018 hard-coded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The age is 53 years old.\n",
      "- The class of worker is Owner of non-incorporated business, professional practice, or farm.\n",
      "- The highest educational attainment is Bachelor's degree.\n",
      "- The marital status is Married.\n",
      "- The occupation is Musicians and singers.\n",
      "- The place of birth is New York.\n",
      "- The relationship to the reference person in the survey is The reference person itself.\n",
      "- The usual number of hours worked per week is 20 hours.\n",
      "- The sex is Male.\n",
      "- The race is White.\n"
     ]
    }
   ],
   "source": [
    "print(acs_task.get_row_description(example_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def get_row_description(self, row: pd.Series) -> str:\n",
    "        \"\"\"Encode a description of a given data row in textual form.\"\"\"\n",
    "        row = row[self.features]\n",
    "        return (\n",
    "            \"\\n\".join(\n",
    "                \"- \" + self.cols_to_text[col].get_text(val)\n",
    "                for col, val in row.items()\n",
    "            )\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The age is 44 years old.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_task.cols_to_text['AGEP'].get_text('44')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def get_text(self, value: object) -> str:\n",
    "        \"\"\"Returns the natural text representation of the given data value.\"\"\"\n",
    "        if self._use_value_map_only:\n",
    "            return self[value]\n",
    "        return f\"The {self.short_description} {self._connector_verb} {self[value]}.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_task.cols_to_text['AGEP']._short_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_task.cols_to_text['AGEP']._connector_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'53 years old'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_task.cols_to_text['AGEP'].value_map('53')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The person is 53 years old.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_task.cols_to_text['AGEP']._verbalize(acs_task.cols_to_text['AGEP'].value_map('53'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"What is this person's estimated yearly income?\",\n",
       " 1,\n",
       " (Choice(text='Below $50,000', data_value=0, numeric_value=None),\n",
       "  Choice(text='Above $50,000', data_value=1, numeric_value=None)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_task.question.text, acs_task.question.num_forward_passes, acs_task.question.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"What is the probability that this person's estimated yearly income is above $50,000 ?\",\n",
       " 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_task.direct_numeric_qa.text, acs_task.direct_numeric_qa.num_forward_passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete zero-shot prompt\n",
    "- using task.get_row_description\n",
    "- using question.get_question_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:{} are currently ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following data corresponds to a survey respondent. The survey was conducted among US residents in 2018. Please answer the question based on the information provided. The data provided is enough to reach an approximate answer.\n",
      "\n",
      "Information:\n",
      "The person is 53 years old. The person is Owner of non-incorporated business, professional practice, or farm. The person is  bachelor's degree. The person is married. The person's occupation is 'Musicians and singers'. The person is born in New York. Relative to the reference person in the survey, the person is the reference person itself. Usually, the person works 20 hours per week. The person identifies as male. The person identifies as White.\n",
      "\n",
      "Question: What is this person's estimated yearly income?\n",
      "A. Below $50,000.\n",
      "B. Above $50,000.\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = prompting.encode_row_prompt(\n",
    "    row=example_row,\n",
    "    task=acs_task,\n",
    "    question=None,\n",
    "    custom_prompt_prefix=None,\n",
    "    add_task_description=True,\n",
    "    prompt_style = {'format':'text', 'connector':'is', 'standardized_sentence': False}, \n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MultipleChoiceQA.get_answer_from_model_output of MultipleChoiceQA(column='PINCP>50000', text=\"What is this person's estimated yearly income?\", num_forward_passes=1, choices=(Choice(text='Below $50,000', data_value=0, numeric_value=None), Choice(text='Above $50,000', data_value=1, numeric_value=None)), _answer_keys_source=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_task.question.get_answer_from_model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m folktexts.cli.launch_experiments_htcondor --executable-path ./folktexts/cli/run_acs_benchmark.py --results-dir ./results/vary-seeds --task ACSMobility --model google/gemma-2-27b-it seed=457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktexts.benchmark import BenchmarkConfig\n",
    "from folktexts.benchmark import Benchmark\n",
    "\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 16\n",
    "DEFAULT_CONTEXT_SIZE = 600\n",
    "DEFAULT_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BenchmarkConfig(\n",
    "        few_shot=False,\n",
    "        numeric_risk_prompting=False,\n",
    "        reuse_few_shot_examples=False,\n",
    "        batch_size=DEFAULT_BATCH_SIZE,\n",
    "        context_size=DEFAULT_CONTEXT_SIZE,\n",
    "        correct_order_bias=False,\n",
    "        feature_subset=None,\n",
    "        population_filter=None,\n",
    "        seed=DEFAULT_SEED,\n",
    "        prompt_style = {'format':'bullet', 'connector':'='}, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkConfig(numeric_risk_prompting=False, few_shot=False, reuse_few_shot_examples=False, batch_size=16, context_size=600, correct_order_bias=False, feature_subset=None, population_filter=None, seed=42, randomize_feature_order=False, prompt_style={'format': 'bullet', 'connector': '='})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktexts.llm_utils import load_model_tokenizer\n",
    "model, tokenizer = load_model_tokenizer('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Received non-standard ACS argument 'subsampling' (using subsampling=0.01 instead of default subsampling=None). This may affect reproducibility.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ACS data...\n",
      "Using zero-shot prompting.\n"
     ]
    }
   ],
   "source": [
    "bench = Benchmark.make_acs_benchmark(\n",
    "        task_name='ACSIncome',\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data_dir=data_dir,\n",
    "        config=config,\n",
    "        subsampling=0.01,\n",
    "        max_api_rpm=False,\n",
    "        prompt_style = {'format':'bullet', 'connector':'='}, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkConfig(numeric_risk_prompting=False, few_shot=False, reuse_few_shot_examples=False, batch_size=16, context_size=600, correct_order_bias=False, feature_subset=None, population_filter=None, seed=42, randomize_feature_order=False, prompt_style={'format': 'bullet', 'connector': '='})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check encoding\n",
    "# print(bench.llm_clf.encode_row(example_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N/A (less than 16 years old, or did not work during the past 12 months)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.task.cols_to_text['WKHP'][corrupted_row['WKHP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The usual number of hours worked per week is N/A (less than 16 years old, or did not work during the past 12 months).'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corrupted_row['WKHP'] in bench.task.cols_to_text['WKHP']._value_map\n",
    "bench.task.cols_to_text['WKHP'].get_text(corrupted_row['WKHP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:{} are currently ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following data corresponds to a survey respondent. The survey was conducted among US residents in 2018. Please answer the question based on the information provided. The data provided is enough to reach an approximate answer.\n",
      "\n",
      "Information:\n",
      "- age = 53 years old\n",
      "- class of worker = Owner of non-incorporated business, professional practice, or farm\n",
      "- highest educational attainment = Bachelor's degree\n",
      "- marital status = Married\n",
      "- occupation = Musicians and singers\n",
      "- place of birth = New York\n",
      "- relationship to the reference person in the survey = The reference person itself\n",
      "- usual number of hours worked per week = N/A (less than 16 years old, or did not work during the past 12 months)\n",
      "- sex = Male\n",
      "- race = White\n",
      "\n",
      "Question: What is this person's estimated yearly income?\n",
      "A. Below $50,000.\n",
      "B. Above $50,000.\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(bench.llm_clf.encode_row(corrupted_row)) # also works with missing values :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing risk estimates:   0%|          | 0/105 [00:00<?, ?it/s]WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "WARNING:root:{} are currently ignored.\n",
      "Computing risk estimates:   0%|          | 0/105 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'vocab_mismatch' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbench\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_root_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results/test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/folktexts-adapted/folktexts/benchmark.py:283\u001b[0m, in \u001b[0;36mBenchmark.run\u001b[0;34m(self, results_root_dir, fit_threshold)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Get LLM risk-estimate predictions for each row in the test set\u001b[39;00m\n\u001b[1;32m    282\u001b[0m test_predictions_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_predictions_save_path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y_test_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredictions_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_predictions_save_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# used only to save alongside predictions in disk\u001b[39;49;00m\n\u001b[1;32m    287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y_test_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_clf\u001b[38;5;241m.\u001b[39m_get_positive_class_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y_test_scores)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# If requested, fit the threshold on a small portion of the train set\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/folktexts-adapted/folktexts/classifier/base.py:287\u001b[0m, in \u001b[0;36mLLMClassifier.predict_proba\u001b[0;34m(self, data, predictions_save_path, labels)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`data` must be a pd.DataFrame, received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Compute risk estimates\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m risk_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_risk_estimates_for_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Save to disk if `predictions_save_path` is provided\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions_save_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/projects/folktexts-adapted/folktexts/classifier/base.py:367\u001b[0m, in \u001b[0;36mLLMClassifier.compute_risk_estimates_for_dataframe\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    357\u001b[0m data_texts_batch \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_row(\n\u001b[1;32m    359\u001b[0m         row,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m batch_data\u001b[38;5;241m.\u001b[39miterrows()\n\u001b[1;32m    364\u001b[0m ]\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Query the model with the batch of data\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m risk_estimates_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_prompt_risk_estimates_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_texts_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Store risk estimates for current question\u001b[39;00m\n\u001b[1;32m    374\u001b[0m batch_risk_scores[:, q_idx] \u001b[38;5;241m=\u001b[39m risk_estimates_batch\n",
      "File \u001b[0;32m~/Documents/projects/folktexts-adapted/folktexts/classifier/transformers_classifier.py:129\u001b[0m, in \u001b[0;36mTransformersLLMClassifier._query_prompt_risk_estimates_batch\u001b[0;34m(self, prompts_batch, question, context_size)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query model with a batch of prompts and return risk estimates.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    The risk estimates for each prompt in the batch.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# TODO: Add support for any unicode character used as a prefix to \" A\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Query model\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m last_token_probs_batch \u001b[38;5;241m=\u001b[39m \u001b[43mquery_model_batch_multiple_passes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_passes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_forward_passes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdigits_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDirectNumericQA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Decode model output\u001b[39;00m\n\u001b[1;32m    139\u001b[0m risk_estimates_batch \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    140\u001b[0m     question\u001b[38;5;241m.\u001b[39mget_answer_from_model_output(\n\u001b[1;32m    141\u001b[0m         ltp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ltp \u001b[38;5;129;01min\u001b[39;00m last_token_probs_batch\n\u001b[1;32m    145\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/projects/folktexts-adapted/folktexts/llm_utils.py:166\u001b[0m, in \u001b[0;36mquery_model_batch_multiple_passes\u001b[0;34m(text_inputs, model, tokenizer, context_size, n_passes, digits_only)\u001b[0m\n\u001b[1;32m    161\u001b[0m last_token_probs_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(last_token_probs)\n\u001b[1;32m    162\u001b[0m last_token_probs_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(last_token_probs_array, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m last_token_probs_array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mlen\u001b[39m(text_inputs), \n\u001b[1;32m    165\u001b[0m     n_passes, \n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mvocab) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mvocab_mismatch\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m actual_vocab_size,)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m last_token_probs_array\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'vocab_mismatch' referenced before assignment"
     ]
    }
   ],
   "source": [
    "bench.run(results_root_dir='./results/test', fit_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(bench.results, indent=4, sort_dicts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktexts.task import TaskMetadata\n",
    "from folktexts.qa_interface import MultipleChoiceQA, Choice\n",
    "from folktexts.col_to_text import ColumnToText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = MultipleChoiceQA(column='target', text='What is the answer?', choices=(Choice(\"Yes\", 0), Choice(\"No\", 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task = TaskMetadata(name=\"task name\", description=\"this is a test task\", features=['t1', 't2'], target='target', cols_to_text={'t1': 'test 1', 't2': 'test 2'}, multiple_choice_qa=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2text = ColumnToText(name='t1', short_description=\"test variable 1\", value_map={0: 'val0', 1:'val1'}, question=question, connector_verb=\"=\", verbalize=lambda x: f\"This is a sentence with {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- a\n",
      "- b\n",
      "- c\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(list(map(lambda s: \"- \"+s, ['a', 'b', 'c']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a, ', 'b, ', 'c, ']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_snippets = []\n",
    "\n",
    "style = 'comma'\n",
    "assert style in [\"text\", \"bullet\", \"comma\"]\n",
    "if style == \"comma\":\n",
    "    apply_structure = lambda s: s + \", \"\n",
    "elif style == \"bullet\":\n",
    "    apply_structure = lambda s: \"\\n- \" + s\n",
    "else:  # full_sentence and style=='text':\n",
    "    apply_structure = lambda s: s\n",
    "\n",
    "for letter in ['a', 'b', 'c']:\n",
    "    text_snippets.append(apply_structure(letter))\n",
    "text_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a, b, c, \n"
     ]
    }
   ],
   "source": [
    "text = \"\".join(text_snippets)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a, b, c\n"
     ]
    }
   ],
   "source": [
    "if text.startswith('\\n'):\n",
    "    text = text[1:]\n",
    "if text.endswith(', '):\n",
    "    text = text[:-2]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monoc-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
